# Modular Architecture Implementation

## Overview

The record deduplication pipeline has been successfully refactored to demonstrate modern software engineering principles with clean separation of concerns. This document summarizes the new modular architecture implemented across all pipeline steps.

## Recent Updates (July 2025)

### üîß **Critical Domain Clustering Fix**
**Issue Resolved**: Fixed a critical bug in hierarchical clustering where all perfect domain matches were assigned identical similarity values (5000.0), causing multiple domains to be incorrectly clustered together.

**Technical Fix**:
- **Problem**: `adaptive_clusterer_v3.py` was setting all perfect domain matches to the same value, making domains indistinguishable
- **Solution**: Modified domain boosting to preserve uniqueness while maintaining priority:
  ```python
  # Before: All perfect matches got identical values
  melted.loc[perfect_domain_mask, "domain_sim"] = 5000.0
  
  # After: Unique incremental values preserve domain identity
  unique_offsets = np.arange(perfect_domain_mask.sum()) * 0.001
  melted.loc[perfect_domain_mask, "domain_sim"] = 4999.0 + unique_offsets
  ```
- **Impact**: Enables proper domain-based subdivision while maintaining aggressive domain prioritization

### üèóÔ∏è **Enhanced Subdivision Engine**
- **Updated**: `subdivision_engine_v3.py` now detects artificially boosted domain values
- **Feature**: Smart handling of boosted values allows subdivision while preserving legitimate uniform clusters
- **Validation**: Added comprehensive test suite for domain boosting logic

### üìä **Project Organization**
- **Completed**: Moved all analysis scripts to `src/scripts/` directory for better organization
- **Updated**: Comprehensive documentation in `src/scripts/README.md`
- **Enhanced**: Git integration with proper commit practices

## Current Implementation Status

‚úÖ **Completed Steps**:
1. **Preprocessing** - Data cleaning and normalization
2. **Blocking** - Candidate pair generation  
3. **Similarity** - Feature computation
4. **Model Training** - ML duplicate scoring (core logic complete)
5. **Clustering** - Advanced hierarchical DBSCAN with domain-aware subdivision
6. **Reporting** - Excel report generation
7. **Domain Clustering** - üÜï Fixed critical domain grouping issue for accurate domain-based clustering

## Architecture Pattern

The new architecture follows a clear separation of concerns:

```
üìÅ src/
‚îú‚îÄ‚îÄ üß† core/           # Pure business logic
‚îú‚îÄ‚îÄ üñ•Ô∏è  formatters/     # Terminal output formatting
‚îú‚îÄ‚îÄ üìÅ io/             # File I/O utilities
‚îî‚îÄ‚îÄ üöÄ cli/            # Command-line interface
```

### Business Logic (`src/core/`)

**Implemented Engines**:
- `preprocess_engine.py` - Data cleaning and normalization
- `blocking_engine.py` - Candidate pair generation
- `similarity_engine.py` - Similarity feature computation
- `model_engine.py` - ML model training and scoring
- `clustering_engine_v2.py` - Advanced hierarchical clustering with modular subdivision

**Clustering Architecture**:
- `hierarchical/core_clusterer.py` - Main hierarchical clustering orchestrator
- `hierarchical/subdivision_engine_v3.py` - Advanced modular subdivision with domain-aware detection
- `hierarchical/adaptive_clusterer_v3.py` - üîß **Fixed**: Domain boosting with uniqueness preservation
- `hierarchical/connectivity_manager.py` - High-similarity connection preservation
- `hierarchical/adaptive_threshold.py` - Intelligent parameter calculation

**Purpose**: Contains pure business logic for each pipeline step
- **Responsibilities**: 
  - Core algorithms and data processing
  - Statistical computations
  - Machine learning operations
  - Business rule implementations
  - Modular clustering strategies
- **Dependencies**: Only pandas, scikit-learn, and core libraries
- **No I/O**: No file reading/writing
- **No UI**: No terminal output or user interaction
- **Testable**: Pure functions that are easy to unit test

**Key Pattern**:
- `*Engine`: Main business logic class
- `*Config`: Configuration data class
- `*Stats`: Statistics data class  
- `*Result`: Result data class

### Terminal Output (`src/formatters/`)

**Location**: `src/formatters/preprocess_formatter.py`

- **Purpose**: Handles all terminal output formatting
- **Responsibilities**:
  - User-friendly progress messages
  - Statistics display and formatting
  - Error message formatting
  - Next-step guidance for users
- **Dependencies**: Only formatting logic
- **Reusable**: Can be used by CLI, web interfaces, or other UIs

**Key Classes:**
- `PreprocessTerminalFormatter`: Formats output for terminal display

### File I/O (`src/io/`)

**Location**: `src/io/file_handler.py`

- **Purpose**: Manages all file reading and writing operations
- **Responsibilities**:
  - CSV/Excel file reading
  - Data file writing with proper error handling
  - Directory creation
  - File format detection
- **Dependencies**: Only pandas and OS libraries
- **Flexible**: Supports multiple file formats

**Key Classes:**
- `FileReader`: Handles reading data files
- `FileWriter`: Handles writing data files

### Command-Line Interface (`src/cli/`)

**Location**: `src/cli/`

- **Purpose**: Orchestrates the flow and handles user interaction
- **Responsibilities**:
  - Argument parsing
  - User input validation
  - Workflow orchestration
  - Error handling and user feedback
- **Dependencies**: Uses all other modules but doesn't contain business logic

**Key Files:**
- `preprocess.py`: CLI for preprocessing step
- `main.py`: Main CLI orchestrator
- `__main__.py`: Makes the CLI package executable

## Usage Examples

### New Modular CLI

```bash
# Use the new modular architecture with enhanced domain clustering
python -m src.cli preprocess data/your_spreadsheet.csv --normalize --deduplicate
python -m src.cli blocking data/outputs/cleaned.csv
python -m src.cli similarity data/outputs/cleaned.csv data/outputs/pairs.csv
python -m src.cli clustering --hierarchical --max-cluster-size 10 --max-depth 20
python -m src.cli reporting

# Enhanced domain clustering with rescue pipeline
python src/scripts/complete_domain_clustering.py --timeout 300 --hierarchical

# Analysis and verification scripts (in src/scripts/)
python src/scripts/verify_perfect_clustering.py
python src/scripts/analyze_domain_clustering.py
python src/scripts/domain_noise_rescue.py

# Get help for any step
python -m src.cli preprocess --help
python -m src.cli clustering --help
python -m src.cli reporting --help
```

### Legacy CLI with New Architecture Option

```bash
# Legacy interfaces still work with new modular components
python -m src.preprocess --input-path data/sample_input.csv
python -m src.blocking data/outputs/cleaned.csv
python -m src.similarity data/outputs/cleaned.csv data/outputs/pairs.csv
python -m src.clustering --hierarchical --max-cluster-size 10 --max-depth 20
python -m src.reporting

# Enhanced domain-aware clustering (recommended for production)
python run_hierarchical_clustering.py
python src/scripts/complete_domain_clustering.py
```

### Programmatic Usage

```python
# Preprocessing example
from src.core.preprocess_engine import PreprocessEngine, PreprocessConfig
from src.io.file_handler import FileReader, FileWriter
from src.formatters.preprocess_formatter import PreprocessTerminalFormatter

engine = PreprocessEngine()
result = engine.process(df, PreprocessConfig(remove_duplicates=True))

# Enhanced hierarchical clustering with domain awareness
from src.core.clustering.hierarchical.adaptive_clusterer_v3 import AdaptiveHierarchicalClusterer
from src.core.clustering.hierarchical.subdivision_engine_v3 import SubdivisionEngineV3

clusterer = AdaptiveHierarchicalClusterer(
    timeout_seconds=300,
    max_cluster_size=10,
    max_depth=20
)

# Domain clustering with fixed boosting logic
result = clusterer.hierarchical_cluster(
    features_df=features_df,
    eps=0.5,
    max_iterations=50
)

# Domain noise rescue pipeline
from src.scripts.domain_noise_rescue import rescue_domain_noise_records

updated_df, rescue_stats = rescue_domain_noise_records(
    clustered_df, 
    features_df,
    domain_threshold=0.85
)

# Reporting example
from src.core.reporting_engine import ReportingEngine
from src.formatters.reporting_formatter import ReportingFormatter

reporting_engine = ReportingEngine()
stats = reporting_engine.generate_report(
    dupes_path="data/outputs/high_confidence.csv",
    cleaned_path="data/outputs/cleaned.csv",
    report_path="data/outputs/manual_review.xlsx"
)

formatter = ReportingFormatter()
print(formatter.format_comprehensive_results(stats, "manual_review.xlsx"))
```

## Benefits of the New Architecture

### 1. **Separation of Concerns**
- Business logic is isolated from I/O and UI concerns
- Each module has a single, clear responsibility
- Changes to one concern don't affect others

### 2. **Testability**
- Pure business logic functions are easy to unit test
- Mock I/O operations without affecting core logic
- Test formatters independently of business logic

### 3. **Reusability**
- Business logic can be used in different contexts (CLI, web API, notebooks)
- Formatters can be swapped (terminal, web, JSON output)
- I/O handlers work across different interfaces

### 4. **Maintainability**
- Clear module boundaries make code easier to understand
- Localized changes reduce risk of breaking other components
- New developers can focus on specific areas

### 5. **Flexibility**
- Easy to add new output formats (JSON, web interface)
- Simple to modify business logic without UI changes
- Can integrate with different data sources

### 6. **üÜï Domain Clustering Accuracy**
- Fixed critical domain boosting bug that prevented proper domain separation
- Intelligent subdivision detection for artificially boosted values
- Preserves domain priority while enabling domain-based clustering
- Comprehensive domain noise rescue capabilities

## üîß Domain Clustering Architecture

### Problem Resolution
The recent update addressed a critical issue where perfect domain matches were being assigned identical similarity values, causing multiple domains to be incorrectly grouped together.

### Technical Implementation
- **Adaptive Clusterer V3**: Enhanced domain boosting with uniqueness preservation
- **Subdivision Engine V3**: Smart detection of boosted vs. legitimate uniform clusters
- **Domain Noise Rescue**: Advanced pipeline for recovering scattered domain records
- **Complete Domain Clustering**: End-to-end workflow with hierarchical subdivision

### Key Features
- **Domain Priority**: Perfect domain matches maintain ultra-high priority (4999+)
- **Uniqueness Preservation**: Each domain pair gets slightly different values for subdivision
- **Subdivision Control**: Engine correctly identifies when subdivision is beneficial
- **Validation Tools**: Comprehensive testing and analysis scripts in `src/scripts/`

## Migration Strategy

The refactoring maintains **full backward compatibility**:

1. **Legacy Interface**: `src/preprocess.py` still works exactly as before
2. **New Architecture Option**: Added `--use-new-architecture` flag to legacy CLI
3. **Gradual Migration**: Teams can migrate step-by-step
4. **Fallback Handling**: Graceful degradation if new modules are unavailable

## Current Status

The following pipeline steps have been successfully modularized:

‚úÖ **Preprocessing** - Completed
- `src/core/preprocess_engine.py` (business logic)
- `src/formatters/preprocess_formatter.py` (terminal output)
- `src/cli/preprocess.py` (CLI orchestration)

‚úÖ **Blocking** - Completed
- `src/core/blocking_engine.py` (business logic)
- `src/formatters/blocking_formatter.py` (terminal output)
- `src/cli/blocking.py` (CLI orchestration)

‚úÖ **Similarity** - Completed
- `src/core/similarity_engine.py` (business logic)
- `src/formatters/similarity_formatter.py` (terminal output)
- `src/cli/similarity.py` (CLI orchestration)

‚úÖ **Model Training** - Completed
- `src/core/model_engine.py` (business logic)
- `src/formatters/model_formatter.py` (terminal output)
- `src/cli/model.py` (CLI orchestration)

‚úÖ **Clustering** - Completed with Enhanced Domain Awareness
- `src/core/clustering_engine_v2.py` (business logic)
- `src/core/clustering/hierarchical/adaptive_clusterer_v3.py` (üîß **FIXED**: domain boosting)
- `src/core/clustering/hierarchical/subdivision_engine_v3.py` (üÜï domain-aware subdivision)
- `src/formatters/clustering_formatter.py` (terminal output)
- `src/cli/clustering.py` (CLI orchestration)

‚úÖ **Reporting** - Completed
- `src/core/reporting_engine.py` (business logic)
- `src/formatters/reporting_formatter.py` (terminal output)
- `src/cli/reporting.py` (CLI orchestration)

## üéâ Modularization Complete with Enhanced Domain Clustering!

All major pipeline steps have been successfully refactored into the modular architecture with critical domain clustering improvements! 

### ‚úÖ Completed Pipeline Steps:
- **Preprocessing**: Full modular implementation with engine, formatter, and CLI
- **Blocking**: Full modular implementation with engine, formatter, and CLI
- **Similarity**: Full modular implementation with engine, formatter, and CLI
- **Model Training**: Full modular implementation with engine, formatter, and CLI
- **Clustering**: üÜï **Enhanced** modular implementation with domain-aware hierarchical clustering
- **Reporting**: Full modular implementation with engine, formatter, and CLI

### ‚úÖ Architecture Features:
- **Main CLI**: Unified CLI supporting all pipeline steps as subcommands
- **Backward Compatibility**: All legacy interfaces still work via bridge pattern
- **File I/O**: Centralized file handling utilities
- **Error Handling**: Robust error handling with automatic fallbacks
- **Data Type Handling**: Smart ID type conversion and mismatch detection
- **üÜï Domain Clustering**: Fixed critical domain boosting bug for accurate domain-based clustering

### üîß Recent Critical Fixes:
- **Domain Boosting Bug**: Fixed issue where all perfect domain matches got identical values
- **Subdivision Logic**: Enhanced to handle artificially boosted values correctly
- **Domain Rescue**: Advanced pipeline for recovering scattered domain records
- **Project Organization**: All scripts moved to `src/scripts/` with comprehensive documentation

### üìä Performance Improvements:
- **Clustering Accuracy**: Proper domain separation while maintaining domain priority
- **Subdivision Efficiency**: Smart detection prevents unnecessary subdivision of legitimate clusters
- **Validation Tools**: Comprehensive test suite for domain clustering logic
- **Analysis Scripts**: Complete set of tools for cluster analysis and verification

The modular architecture is now production-ready with robust domain clustering and provides:
- Clean separation of concerns (business logic, UI, I/O)
- Full backward compatibility with existing interfaces
- Enhanced domain-aware clustering capabilities
- Easy testing and maintenance
- Flexible integration options (CLI, web, API, notebooks)

Optional future improvements:
1. Add more comprehensive test coverage for edge cases
2. Add web interface using the modular components
3. Create Jupyter notebook examples using the engine classes
4. Add configuration file support for complex workflows
5. üÜï Further optimize domain clustering for extremely large datasets
6. üÜï Add more sophisticated domain similarity metrics beyond exact matching

## Example: Current vs. New Architecture

### Before (Monolithic)
```python
# In src/preprocess.py - everything mixed together
def main(input_path, output_path, ...):
    # File I/O
    df = pd.read_csv(input_path)
    
    # Business logic
    df['company_clean'] = df['company'].apply(normalize_company_name)
    
    # Terminal output
    print(f"Processed {len(df)} records")
    
    # More file I/O
    df.to_csv(output_path)
    
    # More terminal output
    print("Complete!")
```

### After (Modular)
```python
# Business logic in src/core/preprocess_engine.py
class PreprocessEngine:
    def process(self, df, config):
        # Pure business logic only
        pass

# Terminal output in src/formatters/preprocess_formatter.py  
class PreprocessTerminalFormatter:
    def format_results(self, result, ...):
        # Only formatting logic
        pass

# File I/O in src/io/file_handler.py
class FileReader:
    def read_data(self, path):
        # Only file reading logic
        pass

# CLI orchestration in src/cli/preprocess.py
class PreprocessCLI:
    def run(self, args):
        # Orchestrates flow, no business logic
        df = self.file_reader.read_data(args.input)
        result = self.engine.process(df, config)
        self.file_writer.write_csv(result.cleaned_df, args.output)
        self.formatter.format_results(result, ...)
```

## Code Quality Improvements

- **Single Responsibility**: Each class has one clear purpose
- **Dependency Injection**: Components can be easily swapped
- **Pure Functions**: Business logic functions have no side effects
- **Clear Interfaces**: Well-defined contracts between modules
- **Error Handling**: Centralized and consistent error management
- **Documentation**: Each module is self-documenting

This refactoring demonstrates how to modernize legacy code while maintaining backward compatibility and providing a foundation for future enhancements.
